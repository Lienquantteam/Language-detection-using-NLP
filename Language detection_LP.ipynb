{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "from random import shuffle\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "\n",
    "# model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove some special characters\n",
    "def remove_special_chars(sen, filter_chars):\n",
    "    sen = sen.strip()\n",
    "    sen = sen.lower()\n",
    "    for each in sen:\n",
    "        num_ascii = ord(each)\n",
    "        # delete number, \".\", \"\\\", all chars in filter_chars\n",
    "        if (num_ascii > 47 and num_ascii < 58) or num_ascii == 92 or num_ascii == 46 or (each in filter_chars):\n",
    "            sen = sen.replace(each, \"\")\n",
    "    return sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file csv and convert it to pandasframe\n",
    "def open_file(name):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    with open('{file_name}.csv'.format(file_name = \"formatted_data\"), encoding='Latin1') as f:\n",
    "        content = f.readlines()\n",
    "    # you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "    content = [x.strip() for x in content] # mỗi\n",
    "\n",
    "    data = []\n",
    "    for num, each in enumerate(content):\n",
    "        each = each.split(\";\")\n",
    "\n",
    "        if \".\" in each[1]:\n",
    "            sentences = each[1].split(\".\") \n",
    "            filter_chars = ['\\t', '!', '\"', '%', '&', '*', '+', ',', '-', '/', ':', '=', '?', '@', '[', ']', '§', \n",
    "                            '«', \"”\", \"\\\\\", \".\", '»']\n",
    "                    \n",
    "            for number, sen in enumerate(sentences):\n",
    "                \"\"\"\n",
    "                insert remove special characters\n",
    "\n",
    "                \"\"\"\n",
    "\n",
    "                # filter no meaning words\n",
    "                sen = remove_special_chars(sen, filter_chars)\n",
    "\n",
    "                # make sure a sentence have len(sentence) > 0\n",
    "                if len(sen)>0:\n",
    "                    data.append([each[0], sen, each[2]])\n",
    "\n",
    "        else:\n",
    "            data.append(each)\n",
    "\n",
    "    main_data = data[1:]\n",
    "    main_data = shuffle(main_data)\n",
    "    df = pd.DataFrame(main_data, columns = data[0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = open_file('formatted_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>text</th>\n",
       "      <th>length_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fi</td>\n",
       "      <td>komissio on kuitenkin sitã¤ mieltã¤ ettã¤ meid...</td>\n",
       "      <td>694523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>de</td>\n",
       "      <td>die artikel</td>\n",
       "      <td>747690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>we have to get this right</td>\n",
       "      <td>690268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fr</td>\n",
       "      <td>dans ce domaine il y a selon moi certaines zon...</td>\n",
       "      <td>756201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sk</td>\n",
       "      <td>schvã¡lenie zã¡pisnice z predchã¡dzajãºceho ro...</td>\n",
       "      <td>328185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                                               text length_text\n",
       "0       fi  komissio on kuitenkin sitã¤ mieltã¤ ettã¤ meid...      694523\n",
       "1       de                                       die artikel       747690\n",
       "2       en                          we have to get this right      690268\n",
       "3       fr  dans ce domaine il y a selon moi certaines zon...      756201\n",
       "4       sk  schvã¡lenie zã¡pisnice z predchã¡dzajãºceho ro...      328185"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78160, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fi\n",
      "mietintã¶ todistaa kuitenkin ettã¤ alueelliset erot tyã¶markkinoilla ovat jopa syventyneet entisestã¤ã¤n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get data in a row\n",
    "def get_data(df = df, row = 60000):\n",
    "    return  df.iloc[row][0], df.iloc[row][1]\n",
    "\n",
    "label, text = get_data(row = 700)\n",
    "print(label)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LIEN PHAM\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# vectorize sentences and split it in to train and test file\n",
    "def vectorization(df, test_size=0.2):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(list(df[\"text\"]), list(df[\"language\"]), test_size=test_size, random_state=42)\n",
    "\n",
    "    # vectorize sentence X\n",
    "    count_vectorizer = CountVectorizer(analyzer='char')\n",
    "    X_train_features = count_vectorizer.fit_transform(X_train)\n",
    "    X_test_features = count_vectorizer.transform(X_test)\n",
    "\n",
    "    # vectorize label Y\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    y_train_features = label_encoder.fit_transform(y_train)\n",
    "    y_test_features = label_encoder.transform(y_test)\n",
    "    \n",
    "    # getted features\n",
    "    features = count_vectorizer.get_feature_names()\n",
    "    \n",
    "    # getted labels\n",
    "    labels = list(label_encoder.classes_)\n",
    "    \n",
    "    return X_train_features, y_train_features, X_test_features, y_test_features, features, labels, count_vectorizer\n",
    "\n",
    "X_train_features, y_train_features, X_test_features, y_test_features, features, labels, count_vectorizer = vectorization(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec, fasttext, bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:  [' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\x80', '\\x81', '\\x82', '\\x83', '\\x84', '\\x85', '\\x86', '\\x87', '\\x88', '\\x89', '\\x8a', '\\x8b', '\\x8c', '\\x8d', '\\x8e', '\\x8f', '\\x90', '\\x91', '\\x92', '\\x93', '\\x94', '\\x95', '\\x96', '\\x97', '\\x98', '\\x99', '\\x9a', '\\x9b', '\\x9c', '\\x9d', '\\x9e', '\\x9f', '\\xa0', '¡', '¢', '£', '¤', '¥', '¦', '¨', '©', 'ª', '¬', '\\xad', '®', '¯', '°', '±', '²', '³', '´', 'µ', '¶', '·', '¸', '¹', 'º', '¼', '½', '¾', '¿', 'â', 'ã', 'ä', 'å', 'è', 'î', 'ï', 'ð', 'ñ']\n",
      "\n",
      "Len features:  97\n"
     ]
    }
   ],
   "source": [
    "# number of the features\n",
    "print(\"features: \", features)\n",
    "print(\"\\nLen features: \", len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23, 12,  2,  9,  5, 11,  2,  1,  1, 15,  0,  0,  9,  4,  5, 11,  4,\n",
       "        0, 10,  4, 13, 11,  0,  0,  0,  0,  2,  0,  0,  0,  3,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0,  1,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  1,  3,  3,  0,  0,  0,  0,  0], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_features.toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9230441160857645\n"
     ]
    }
   ],
   "source": [
    "# create and training model MultinomialNB\n",
    "modelNB = MultinomialNB()\n",
    "modelNB.fit(X_train_features, y_train_features)\n",
    "\n",
    "# model accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy: \",f1_score(y_test_features, modelNB.predict(X_test_features), average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the classifier\n",
    "with open('modelNB.pkl', 'wb') as fid:\n",
    "    pickle.dump(modelNB, fid) \n",
    "    \n",
    "# load it again\n",
    "with open('modelNB.pkl', 'rb') as fid:\n",
    "    modelNB = pickle.load(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3, 16,  0, ..., 13,  2,  4], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict from saved model\n",
    "modelNB.predict(X_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Model Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9413382804503583\n"
     ]
    }
   ],
   "source": [
    "# model Random Forest\n",
    "modelRF=RandomForestClassifier(n_estimators=100)\n",
    "modelRF.fit(X_train_features,y_train_features)\n",
    "\n",
    "y_pred = modelRF.predict(X_test_features)\n",
    "\n",
    "# model accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test_features, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the classifier\n",
    "with open('modelRF.pkl', 'wb') as fid:\n",
    "    pickle.dump(modelRF, fid) \n",
    "    \n",
    "# load it again\n",
    "with open('modelRF.pkl', 'rb') as fid:\n",
    "    modelRF = pickle.load(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, 16,  0, ..., 13,  2,  4], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict from saved model\n",
    "modelRF.predict(X_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Optimize parametters for random forest model, accuracy can be better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal paras:  {'max_features': 'log2', 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# tuning model by grid search cv\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=RandomForestClassifier(), n_jobs = -1, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(X_train_features, y_train_features)\n",
    "\n",
    "# choose the best parametters \n",
    "print(\"Optimal paras: \", CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features='log2', n_estimators=300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create random forest model with the optimal parametter\n",
    "optimal_modelRF=RandomForestClassifier(n_estimators=300, max_features= 'log2')\n",
    "\n",
    "#Train the model using the training sets \n",
    "optimal_modelRF.fit(X_train_features,y_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9437691914022518\n"
     ]
    }
   ],
   "source": [
    "# find the accuracy\n",
    "y_pred = optimal_modelRF.predict(X_test_features)\n",
    "\n",
    "# model accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test_features, y_pred)) #Accuracy: 0.9437691914022518"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the classifier\n",
    "with open('optimal_modelRF.pkl', 'wb') as fid:\n",
    "    pickle.dump(optimal_modelRF, fid) \n",
    "    \n",
    "# load it again\n",
    "with open('optimal_modelRF.pkl', 'rb') as fid:\n",
    "    optimal_modelRF = pickle.load(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Model support vector machine - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 656    0    0    4    0    5    2    0    0    1    0    1    0    0\n",
      "     0    0    0    5    0    0    0]\n",
      " [  13  470    1    2    1    2    2    2    0    0    4    0    1    0\n",
      "     0    0    1    1   17    2    0]\n",
      " [   1    0 1000    4    0    2    2    0    0    2    0    1    1    3\n",
      "    12    0    0    0    0    0   13]\n",
      " [   2    0   11  882    0    5    0    4    0    0    0    1    1    5\n",
      "    15    2    0    1    0    1    4]\n",
      " [   2    0    1    0  587    0    1    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0]\n",
      " [   1    0    5   10    0  876    9    0    0    2    0    3    6    4\n",
      "     8    0    0    0    0    0    0]\n",
      " [   0    0    7    2    0    7  870    0    0   15    2    3    1    2\n",
      "     1    0   17    1    1    0    0]\n",
      " [   2    0    4    5    0    3    7  472    9    1    0    0    2    4\n",
      "     1    0    1    2    0    2    3]\n",
      " [   0    0    2    1    0    0    1    7  915    1    0    0    0    0\n",
      "     0    0    0    0    0    0    1]\n",
      " [   1    0    4    1    0    3    9    0    0  879    0    5    6    1\n",
      "     3    0    5    3    1    0    0]\n",
      " [   9    2    0    7    0    2    2    1    0    2  467    1    0    2\n",
      "     0    0    2    6    2    0    0]\n",
      " [   0    2    1    0    0    2   12    2    0    6    0  802    0    0\n",
      "     2    0    5    3    0    0    0]\n",
      " [   4    2    2    1    0    4    7    9    1    1    0    2  667    8\n",
      "     0    2    0    9    2    2    0]\n",
      " [   7    1    4    5    0    0    2    2    0    1    1    0   12  672\n",
      "     1    1    0    6    0    4    0]\n",
      " [   0    0   23   14    0    6    5    0    0    0    0    4    2    3\n",
      "  1001    1    0    0    1    6    1]\n",
      " [   7    0    0    3    0    7    4    1    0    0    1    1    1    4\n",
      "     0  445    0    3    0    0    0]\n",
      " [   0    0    1    0    0    3   38    0    0    4    0    4    2    0\n",
      "     0    0  835    2    1    0    1]\n",
      " [  15    0    1    5    0    3    5    1    0    3    1    8    1    1\n",
      "     3    0    1  409    0    0    0]\n",
      " [   9    8    2    5    0    2    4    5    2    0    4    0    3    5\n",
      "     2    0    0    6  452    5    0]\n",
      " [   5    0    1    5    0    3    3    4    0    4    1    2    5    4\n",
      "     9    0    1    3    3  486    1]\n",
      " [   0    0   14    3    0    0    1    6    1    0    0    0    0    3\n",
      "     1    0    0    0    0    0  894]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93       674\n",
      "           1       0.97      0.91      0.94       519\n",
      "           2       0.92      0.96      0.94      1041\n",
      "           3       0.92      0.94      0.93       934\n",
      "           4       1.00      0.99      1.00       591\n",
      "           5       0.94      0.95      0.94       924\n",
      "           6       0.88      0.94      0.91       929\n",
      "           7       0.91      0.91      0.91       518\n",
      "           8       0.99      0.99      0.99       928\n",
      "           9       0.95      0.95      0.95       921\n",
      "          10       0.97      0.92      0.95       505\n",
      "          11       0.96      0.96      0.96       837\n",
      "          12       0.94      0.92      0.93       723\n",
      "          13       0.93      0.93      0.93       719\n",
      "          14       0.95      0.94      0.94      1067\n",
      "          15       0.99      0.93      0.96       477\n",
      "          16       0.96      0.94      0.95       891\n",
      "          17       0.89      0.89      0.89       457\n",
      "          18       0.94      0.88      0.91       514\n",
      "          19       0.96      0.90      0.93       540\n",
      "          20       0.97      0.97      0.97       923\n",
      "\n",
      "    accuracy                           0.94     15632\n",
      "   macro avg       0.94      0.94      0.94     15632\n",
      "weighted avg       0.94      0.94      0.94     15632\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_SVM = SVC(kernel='linear')\n",
    "model_SVM.fit(X_train_features, y_train_features)\n",
    "\n",
    "y_pred = model_SVM.predict(X_test_features)\n",
    "\n",
    "print(confusion_matrix(y_test_features,y_pred))\n",
    "print(classification_report(y_test_features,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Find the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = list(df[\"text\"]), list(df[\"language\"])\n",
    "\n",
    "# vectorize sentence X\n",
    "vectorizer = CountVectorizer(analyzer='char')\n",
    "X_features = count_vectorizer.fit_transform(X)\n",
    "\n",
    "# vectorize label Y\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "Y_features = label_encoder.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200),\n",
    "    SVC(),\n",
    "    GaussianNB(),\n",
    "    LogisticRegression(),\n",
    "]\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models))) # no need\n",
    "entries = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9,  0,  0, ...,  0,  0,  0],\n",
       "       [ 2,  1,  0, ...,  0,  0,  0],\n",
       "       [ 5,  1,  0, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [10,  0,  0, ...,  0, 59, 16],\n",
       "       [21,  0,  0, ..., 41,  0,  0],\n",
       "       [10,  9,  1, ...,  0,  0,  0]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 3, 5, ..., 0, 4, 6], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_features.toarray()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78160"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_features.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78160"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94172211 0.94121034 0.94037871 0.94089048 0.94082651]\n",
      "[0.90084442 0.89495906 0.90007677 0.89905322 0.89636643]\n",
      "[0.79881013 0.80188076 0.80040942 0.80098516 0.81275589]\n",
      "[0.93519703 0.93046315 0.93423746 0.93353378 0.93142272]\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    accuracies = cross_val_score(model, \n",
    "                                 X_features.toarray(), \n",
    "                                 Y_features, \n",
    "                                 scoring='accuracy', \n",
    "                                 cv=CV, \n",
    "                                 n_jobs=-1                                \n",
    "                                 )\n",
    "    print(accuracies)    \n",
    "    entries.append([model_name, sum(accuracies)/len(accuracies)])\n",
    "\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.941006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.898260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.802968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.932971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model_name  accuracy\n",
       "0  RandomForestClassifier  0.941006\n",
       "1                     SVC  0.898260\n",
       "2              GaussianNB  0.802968\n",
       "3      LogisticRegression  0.932971"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.94079284 0.9434638  0.9470957  0.9484226  0.937408  ]\n",
    "[0.91432225 0.91385265 0.91613357 0.92116209 0.913344  ]\n",
    "[0.81675192 0.82693784 0.82970829 0.81928713 0.81888   ]\n",
    "[0.93842711 0.93789972 0.9392912  0.94176745 0.930752  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name\taccuracy\n",
    "0\tRandomForestClassifier\t0.941006\n",
    "1\tSVC\t0.898260\n",
    "2\tGaussianNB\t0.802968\n",
    "3\tLogisticRegression\t0.932971"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comments: RF has highest accuracy rate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
